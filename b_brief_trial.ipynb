{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import os,sys \n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path=\"/home/user/xsj/LLMTaskPlanning/alfred_multiagent/data/json_2.1.0/\"\n",
    "\n",
    "root_path_len=len(root_path)\n",
    "# with open(os.path.join(root_path,'../../scene_dict.json'),'w') as f :\n",
    "#     f.write(json.dumps(scene_dict,sort_keys=False,indent=4,separators=(',',':')))\n",
    "with open(os.path.join(root_path,'../../scene_dict.json'),'r') as f :\n",
    "    scene_dict=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepaths=[]\n",
    "# for root, dirs,files in os.walk(root_path):\n",
    "#     for filename in files:\n",
    "#         if \"json\" in filename:\n",
    "#             filepaths.append(os.path.join(root,filename)[root_path_len:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from NL2HLTLtaskPlanner import utils as util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPTinterface=util.GPTinterface(\n",
    "            useFakeGPTAPI=(not True),\n",
    "            readFromFormerLog=False,\n",
    "            logger=None,\n",
    "            TranslateNL2TLInterface=util.NL2TLTranslater(\n",
    "                    machine_type='openaiAPI',\n",
    "                    base_url = \"127.0.0.1:8000\"\n",
    "                # communicatorWithServer=util.communicator.communicationViaSSH(\n",
    "                #     connectCommand=\"mill19\",\n",
    "                #     serverFolderPath='/home/icl-mill19/xsj/model_weight/scp-folder',\n",
    "                #     clientFolderPath='/home/icl-mill19/xsj/NL2HLTL/exp',\n",
    "                #     fileName='prompt.txt',)\n",
    "                    ),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_flag=True\n",
    "trial_count=0\n",
    "for scene_name in scene_dict.keys():\n",
    "    for trial_path in np.sort(scene_dict[scene_name]):\n",
    "        try:\n",
    "            new_path=os.path.join(root_path,'../../task_wo_position/{}.json'.format(trial_path))\n",
    "            if not os.path.exists(new_path):\n",
    "                os.makedirs(os.path.dirname(new_path))\n",
    "            else:\n",
    "                # print('{} exists'.format(trial_path))\n",
    "                continue\n",
    "            with open(os.path.join(root_path,trial_path),'r') as f:\n",
    "                trial=json.load(f)\n",
    "            trial_names= [re.match(\"([a-zA-Z]+)\",x[\"objectName\"]).group(0) for x in trial[\"scene\"][\"object_poses\"]]\n",
    "            trial_tasks= [x[\"task_desc\"] for x in trial[\"turk_annotations\"][\"anns\"]]\n",
    "            prompt=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\":\"\"\"according to the task {} and the breakdown of execution steps {}\\n currently in the environment we have the following objects, please extract all objects that may be involved in completing this task {}. Please return in JSON\n",
    "    ```json\n",
    "    {{\n",
    "        \"relative_objects\": [object 1, object 2, ...],\n",
    "        \"explanation\":\n",
    "    }},\n",
    "    ```\n",
    "    Please consider carefully and provide the most reasonable answer.\n",
    "    \"\"\".format(\"; \".join(trial_tasks),\"\",\", \".join(trial_names))\n",
    "    }\n",
    "                ]\n",
    "            # print(prompt)\n",
    "\n",
    "            ret=GPTinterface.communicate(prompt,task_stage='Q_envInfoExtraction',modelVersion='3',print_screen=False)\n",
    "            jsonstr=util.splitJSONfromTXT(ret)[-1]\n",
    "            # print(jsonstr)\n",
    "            \n",
    "\n",
    "\n",
    "            with open(new_path,'w') as f :\n",
    "                f.write(json.dumps(json.loads(jsonstr),sort_keys=False,indent=4,separators=(',',':')))\n",
    "            trial_count+=1\n",
    "            print(trial_count,trial_path)\n",
    "        except:\n",
    "            pass\n",
    "        # check_flag=False\n",
    "        if check_flag==False:\n",
    "            break\n",
    "    if check_flag==False:\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
